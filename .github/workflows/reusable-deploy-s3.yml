name: Reusable Deploy to S3

on:
  workflow_call:
    inputs:
      artifact-name:
        description: 'Name of the build artifact to deploy'
        required: false
        type: string
        default: 'build.tgz'
      s3-bucket:
        description: 'S3 bucket name'
        required: true
        type: string
      build-dir:
        description: 'Build directory to sync'
        required: false
        type: string
        default: './build'
      additional-files:
        description: 'Additional files to copy (comma-separated, e.g., robots.txt,sitemap.xml)'
        required: false
        type: string
        default: ''
      aws-region:
        description: 'AWS region'
        required: false
        type: string
        default: 'ap-northeast-1'
    secrets:
      AWS_ACCESS_KEY_ID:
        description: 'AWS Access Key ID'
        required: true
      AWS_SECRET_ACCESS_KEY:
        description: 'AWS Secret Access Key'
        required: true

jobs:
  deploy:
    runs-on: ubuntu-latest
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_DEFAULT_REGION: ${{ inputs.aws-region }}
      AWS_PAGER: ""
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Docker Compose
        run: docker compose up -d

      - name: Download build artifact
        uses: actions/download-artifact@v4
        with:
          name: ${{ inputs.artifact-name }}

      - name: Extract and sync to S3
        run: |
          tar xvfz ./${{ inputs.artifact-name }}
          docker compose exec -T node aws s3 sync --exact-timestamps ${{ inputs.build-dir }} s3://${{ inputs.s3-bucket }}

      - name: Copy additional files
        if: inputs.additional-files != ''
        run: |
          IFS=',' read -ra FILES <<< "${{ inputs.additional-files }}"
          for file in "${FILES[@]}"; do
            file=$(echo "$file" | xargs)
            if [ -f "$file" ]; then
              echo "Copying $file to S3..."
              docker compose exec -T node aws s3 cp ./$file s3://${{ inputs.s3-bucket }}
            else
              echo "Warning: $file not found, skipping..."
            fi
          done

      - name: Cleanup
        run: docker compose down
        if: always()
